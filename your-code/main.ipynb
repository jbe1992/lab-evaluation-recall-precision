{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Precision & Recall\n",
    "## Using the evaluation metrics we have learned, we are going to compare how well some different types of classifiers perform on different evaluation metrics\n",
    "### We are going to use a dataset of written numbers which we can import from sklearn. Run the code below to do so. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function fetch_mldata is deprecated; fetch_mldata was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function mldata_filename is deprecated; mldata_filename was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now take a look at the shapes of the X and y matricies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's pick one entry and see what number is written. Use indexing to pick the 36000th digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  86, 131, 225, 225, 225,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  13,  73, 197, 253, 252, 252, 252, 252,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         4,  29,  29, 154, 187, 252, 252, 253, 252, 252, 233, 145,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  29, 252, 253, 252, 252, 252, 252, 253, 204, 112,  37,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0, 169, 253, 255, 253, 228, 126,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  98, 243, 252, 253, 252, 246, 130,  38,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,  98, 240, 252, 252, 253, 252, 252,\n",
       "       252, 221,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0, 225, 252, 252, 236, 225,\n",
       "       223, 230, 252, 252,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 146, 252, 157,\n",
       "        50,   0,   0,  25, 205, 252,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  26, 207, 253,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  29,  19,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  73, 205, 252,  79,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 120, 215, 209,\n",
       "       175,   0,   0,   0,   0,   0,   0,   0,  19, 209, 252, 220,  79,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 174,\n",
       "       252, 252, 239, 140,   0,   0,   0,   0,   0,  29, 104, 252, 249,\n",
       "       177,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0, 174, 252, 252, 223,   0,   0,   0,   0,   0,   0, 174, 252,\n",
       "       252, 223,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0, 141, 241, 253, 146,   0,   0,   0,   0, 169, 253,\n",
       "       255, 253, 253,  84,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0, 178, 252, 154,  85,  85, 210, 225,\n",
       "       243, 252, 215, 121,  27,   9,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  66, 208, 220, 252, 253,\n",
       "       252, 252, 214, 195,  31,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  19,  37,\n",
       "        84, 146, 223, 114,  28,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can use the .reshape(28,28) function and plt.imshow() function with the parameters cmap = matplotlib.cm.binary, interpolation=\"nearest\" to make a plot of the number. Be sure to import matplotlib!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12ea18c88>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADcBJREFUeJzt3WGMVfWZx/Hfo5YXShPEuUtAlKkNmBiSUnNDNqnZdN1tY6UG+wbxBc4mptMXxUjEpMQmroY3ZF1tamKa0GXSYe3aaloCRrKti5sQkrV6NSJYt0hxEMjIDNDY6QvSxT77Yg7NqHP/53LPOffc4fl+ksnce55z7nlymR/n3vs/9/zN3QUgnivqbgBAPQg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgrurlzgYGBnxwcLCXuwRCGRsb05kzZ6yTdQuF38zukPRDSVdK+jd335Zaf3BwUK1Wq8guASQ0m82O1+36Zb+ZXSnpGUnfkHSLpHvN7JZuHw9AbxV5z79a0lF3P+buf5b0M0lry2kLQNWKhP96SSdm3D+ZLfsEMxs2s5aZtSYnJwvsDkCZKv+03923u3vT3ZuNRqPq3QHoUJHwn5J0w4z7S7NlAOaAIuF/XdJyM/uCmc2TtF7SnnLaAlC1rof63P2CmW2U9CtND/WNuPs7pXUGoFKFxvndfa+kvSX1AqCHOL0XCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoArN0mtmY5KmJH0s6YK7N8toCujE888/n6wfOnSobW3nzp1lt/MJx48fr/Txy1Ao/Jm/d/czJTwOgB7iZT8QVNHwu6Rfm9kbZjZcRkMAeqPoy/7b3P2Umf2NpJfN7H/dff/MFbL/FIYl6cYbbyy4OwBlKXTkd/dT2e8JSbskrZ5lne3u3nT3ZqPRKLI7ACXqOvxmdo2Zff7ibUlfl3S4rMYAVKvIy/5FknaZ2cXH+Q93/89SugJQua7D7+7HJH2pxF5wGZqammpbO3DgQHLbrVu3Juuvvvpqsp4dmNAGQ31AUIQfCIrwA0ERfiAowg8ERfiBoMr4Vh/62IULF5L18fHxQo+fNxz3/vvvt6298sorhfZdpYGBgWR9/fr1PeqkOhz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAoxvkvc3nj+IODg8m6uyfr/fy12VWrVrWtbdiwIbntmjVrkvXly5d31VM/4cgPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0Exzn+Ze/jhh5P1vHH8vHqeJUuWtK0ND6end3z00UcL7RtpHPmBoAg/EBThB4Ii/EBQhB8IivADQRF+IKjccX4zG5H0TUkT7r4yW7ZQ0s8lDUoak7TO3f9QXZtIGRkZaVvbu3dvctui38fP2/7s2bNta3lzChw5ciRZX7FiRbKOtE6O/D+RdMenlm2RtM/dl0val90HMIfkht/d90s696nFayWNZrdHJd1dcl8AKtbte/5F7n7x+lAfSlpUUj8AeqTwB34+ffJ32xPAzWzYzFpm1pqcnCy6OwAl6Tb8p81ssSRlvyfareju29296e7NRqPR5e4AlK3b8O+RNJTdHpK0u5x2APRKbvjN7DlJ/yPpZjM7aWb3S9om6Wtm9p6kf8zuA5hDrOj3tS9Fs9n0VqvVs/1dLlLj+JL00EMPta1NTU0V2ned1+1ftmxZsn7s2LHK9j1XNZtNtVqtjv5ROMMPCIrwA0ERfiAowg8ERfiBoAg/EBSX7p4DHn/88WS9yHDeggULkvX58+cn61dckT5+nD9/vm1tYqLtiaGSpOPHjyfrKIYjPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ExTj/HLB27dpk/ZlnnmlbGxoaaluTpI0bNybrt956a7KeZ3x8vG1tzZo1yW0PHjxYaN9I48gPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0Exzj8HPP3004XqdUpd+jvvsuC9vKx8RBz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCo3HF+MxuR9E1JE+6+Mlv2mKRvS5rMVnvE3fdW1WQvnDhxIlm/+uqr29auu+66stu5bKS+k583vXdefffu3cl63nUQouvkyP8TSXfMsvwH7r4q+5nTwQciyg2/u++XdK4HvQDooSLv+Tea2dtmNmJm15bWEYCe6Db8P5L0RUmrJI1LerLdimY2bGYtM2tNTk62Ww1Aj3UVfnc/7e4fu/tfJP1Y0urEutvdvenuzUaj0W2fAErWVfjNbPGMu9+SdLicdgD0SidDfc9J+qqkATM7KemfJX3VzFZJckljkr5TYY8AKpAbfne/d5bFOyropVLbtm1L1kdHR5P1efPmta3ddNNNyW137dqVrM9lZ8+eTda3bNnStnb4cPoF4+DgYDctoUOc4QcERfiBoAg/EBThB4Ii/EBQhB8IKsylu1977bVk/ciRI10/9gcffJCsb968OVl/8sm2Z0fXLu+rzi+99FKynhrOu+qq9J/fypUrk3W+slsMR34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCCrMOH+VFixYkKz38zh+ngcffDBZz7t8dsqSJUsqe2zk48gPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0GFGefPuwz0/Pnzk/Wpqam2tbvuuqublnrinnvuSdZfeOGFZN3dk/W8abRTnnjiia63RXEc+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqNxxfjO7QdJOSYskuaTt7v5DM1so6eeSBiWNSVrn7n+ortVinnrqqWT96NGjyXrq+vTnz59Pbps3lp5n69atyfpHH33Utnbu3Lnktnnj9DfffHOyft9993VdX7hwYXJbVKuTI/8FSZvd/RZJfyvpu2Z2i6Qtkva5+3JJ+7L7AOaI3PC7+7i7v5ndnpL0rqTrJa2VNJqtNirp7qqaBFC+S3rPb2aDkr4s6TeSFrn7eFb6UNNvCwDMER2H38zmS/qFpE3u/seZNZ8+AXzWk8DNbNjMWmbWmpycLNQsgPJ0FH4z+5ymg/9Td/9ltvi0mS3O6oslTcy2rbtvd/emuzcbjUYZPQMoQW74bfrj4B2S3nX3mR+Z75E0lN0eksSlVoE5pJOv9H5F0gZJh8zsrWzZI5K2SXrezO6XdFzSumpa7I1NmzYl66lpuPft25fcdseOHcl6lV+bXbFiRbI+MDCQrD/77LPJ+rJlyy65J/SH3PC7+wFJ7f76/qHcdgD0Cmf4AUERfiAowg8ERfiBoAg/EBThB4IKc+nuPLfffnuynhrLz/va7MGDB5P1/fv3J+svvvhisv7AAw+0ra1blz79YunSpck6Ll8c+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMv7LnmZms2mt1qtnu0PiKbZbKrVanV0AQiO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBUbvjN7AYz+28z+62ZvWNmD2bLHzOzU2b2VvZzZ/XtAihLJ5N2XJC02d3fNLPPS3rDzF7Oaj9w93+trj0AVckNv7uPSxrPbk+Z2buSrq+6MQDVuqT3/GY2KOnLkn6TLdpoZm+b2YiZXdtmm2Eza5lZa3JyslCzAMrTcfjNbL6kX0ja5O5/lPQjSV+UtErTrwyenG07d9/u7k13bzYajRJaBlCGjsJvZp/TdPB/6u6/lCR3P+3uH7v7XyT9WNLq6toEULZOPu03STskvevuT81YvnjGat+SdLj89gBUpZNP+78iaYOkQ2b2VrbsEUn3mtkqSS5pTNJ3KukQQCU6+bT/gKTZrgO+t/x2APQKZ/gBQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCMnfv3c7MJiUdn7FoQNKZnjVwafq1t37tS6K3bpXZ2zJ37+h6eT0N/2d2btZy92ZtDST0a2/92pdEb92qqzde9gNBEX4gqLrDv73m/af0a2/92pdEb92qpbda3/MDqE/dR34ANakl/GZ2h5n9zsyOmtmWOnpox8zGzOxQNvNwq+ZeRsxswswOz1i20MxeNrP3st+zTpNWU299MXNzYmbpWp+7fpvxuucv+83sSklHJH1N0klJr0u6191/29NG2jCzMUlNd699TNjM/k7SnyTtdPeV2bJ/kXTO3bdl/3Fe6+7f65PeHpP0p7pnbs4mlFk8c2ZpSXdL+ifV+Nwl+lqnGp63Oo78qyUddfdj7v5nST+TtLaGPvqeu++XdO5Ti9dKGs1uj2r6j6fn2vTWF9x93N3fzG5PSbo4s3Stz12ir1rUEf7rJZ2Ycf+k+mvKb5f0azN7w8yG625mFouyadMl6UNJi+psZha5Mzf30qdmlu6b566bGa/Lxgd+n3Wbu98q6RuSvpu9vO1LPv2erZ+GazqaublXZplZ+q/qfO66nfG6bHWE/5SkG2bcX5ot6wvufir7PSFpl/pv9uHTFydJzX5P1NzPX/XTzM2zzSytPnju+mnG6zrC/7qk5Wb2BTObJ2m9pD019PEZZnZN9kGMzOwaSV9X/80+vEfSUHZ7SNLuGnv5hH6ZubndzNKq+bnruxmv3b3nP5Lu1PQn/r+X9P06emjT102SDmY/79Tdm6TnNP0y8P80/dnI/ZKuk7RP0nuS/kvSwj7q7d8lHZL0tqaDtrim3m7T9Ev6tyW9lf3cWfdzl+irlueNM/yAoPjADwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUP8P1r5YZLcvzCQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(X[36000],(28,28)), cmap = matplotlib.cm.binary, interpolation = \"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use indexing to see if what the plot shows matches with the outcome of the 36000th index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0  86 131 225 225 225   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  13  73\n",
      "  197 253 252 252 252 252   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   4  29  29 154 187 252\n",
      "  252 253 252 252 233 145   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  29 252 253 252 252 252\n",
      "  252 253 204 112  37   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 169 253 255 253 228 126\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  98 243 252 253 252 246 130\n",
      "   38   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  98 240 252 252 253 252 252 252\n",
      "  221   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 225 252 252 236 225 223 230 252\n",
      "  252   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 146 252 157  50   0   0  25 205\n",
      "  252   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  26 207\n",
      "  253   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  29  19   0   0   0   0   0   0   0   0   0  73 205\n",
      "  252  79   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 120 215 209 175   0   0   0   0   0   0   0  19 209 252\n",
      "  220  79   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 174 252 252 239 140   0   0   0   0   0  29 104 252 249\n",
      "  177   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 174 252 252 223   0   0   0   0   0   0 174 252 252 223\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 141 241 253 146   0   0   0   0 169 253 255 253 253  84\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 178 252 154  85  85 210 225 243 252 215 121  27   9\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  66 208 220 252 253 252 252 214 195  31   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  19  37  84 146 223 114  28   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(np.reshape(X[36000],(28,28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets break into a test train split to run a classification. Instead of using sklearn, use indexing to select the first 60000 entries for the training, and the rest for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:60000]\n",
    "X_test = X[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to make a two-class classifier, so lets restrict to just one number, for example 5s. Do this by defining a new y training and y testing sets for just the number 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1.0: 7877, 7.0: 7293, 3.0: 7141, 2.0: 6990, 9.0: 6958, 0.0: 6903, 6.0: 6876, 8.0: 6825, 4.0: 6824, 5.0: 6313})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(y))\n",
    "y_target = y\n",
    "y_target = np.array(list(map(lambda x: 1 if x == 5.0 else 0,y_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 63687, 1: 6313})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_target) # We saw that we have 6313 ones so it is done well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_target[:60000]\n",
    "y_test = y_target[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 60000, 10000, 10000)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(y_train),len(X_test),len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets train a logistic regression to predict if a number is a 5 or not (remember to use the 'just 5s' y training set!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the classifier predict correctly the 36000th digit we picked before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[36000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yes it predicted well. 1 is true and we wanted to get the 5s only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To make some comparisons, we are going to make a very dumb classifier, that never predicts 5s. Build the classifier with the code below, and call it using: never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "\n",
    "never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets fit and predict on the testing set using our never 5 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n5class = Never5Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n5class.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = n5class.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare this to the Logistic Regression. Examine the confusion matrix, precision, recall, and f1_scores for each. What is the probability cutoff you are using to decide the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6843   60    0    0    0    0    0    0    0    0]\n",
      " [7860   17    0    0    0    0    0    0    0    0]\n",
      " [6979   11    0    0    0    0    0    0    0    0]\n",
      " [6990  151    0    0    0    0    0    0    0    0]\n",
      " [6818    6    0    0    0    0    0    0    0    0]\n",
      " [1020 5293    0    0    0    0    0    0    0    0]\n",
      " [6770  106    0    0    0    0    0    0    0    0]\n",
      " [7281   12    0    0    0    0    0    0    0    0]\n",
      " [6710  115    0    0    0    0    0    0    0    0]\n",
      " [6931   27    0    0    0    0    0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.11      0.99      0.19      6903\n",
      "         1.0       0.00      0.00      0.00      7877\n",
      "         2.0       0.00      0.00      0.00      6990\n",
      "         3.0       0.00      0.00      0.00      7141\n",
      "         4.0       0.00      0.00      0.00      6824\n",
      "         5.0       0.00      0.00      0.00      6313\n",
      "         6.0       0.00      0.00      0.00      6876\n",
      "         7.0       0.00      0.00      0.00      7293\n",
      "         8.0       0.00      0.00      0.00      6825\n",
      "         9.0       0.00      0.00      0.00      6958\n",
      "\n",
      "   micro avg       0.10      0.10      0.10     70000\n",
      "   macro avg       0.01      0.10      0.02     70000\n",
      "weighted avg       0.01      0.10      0.02     70000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(y, y_pred))\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6903    0    0    0    0    0    0    0    0    0]\n",
      " [7877    0    0    0    0    0    0    0    0    0]\n",
      " [6990    0    0    0    0    0    0    0    0    0]\n",
      " [7141    0    0    0    0    0    0    0    0    0]\n",
      " [6824    0    0    0    0    0    0    0    0    0]\n",
      " [6313    0    0    0    0    0    0    0    0    0]\n",
      " [6876    0    0    0    0    0    0    0    0    0]\n",
      " [7293    0    0    0    0    0    0    0    0    0]\n",
      " [6825    0    0    0    0    0    0    0    0    0]\n",
      " [6958    0    0    0    0    0    0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.10      1.00      0.18      6903\n",
      "         1.0       0.00      0.00      0.00      7877\n",
      "         2.0       0.00      0.00      0.00      6990\n",
      "         3.0       0.00      0.00      0.00      7141\n",
      "         4.0       0.00      0.00      0.00      6824\n",
      "         5.0       0.00      0.00      0.00      6313\n",
      "         6.0       0.00      0.00      0.00      6876\n",
      "         7.0       0.00      0.00      0.00      7293\n",
      "         8.0       0.00      0.00      0.00      6825\n",
      "         9.0       0.00      0.00      0.00      6958\n",
      "\n",
      "   micro avg       0.10      0.10      0.10     70000\n",
      "   macro avg       0.01      0.10      0.02     70000\n",
      "weighted avg       0.01      0.10      0.02     70000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y, y_pred2))\n",
    "print(classification_report(y, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the differences you see? Without knowing what each model is, what can these metrics tell you about how well each works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's examine the roc_curve for each. Use the roc_curve method from sklearn.metrics to help plot the curve for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now find the roc_auc_score for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this metric tell you? Which classifier works better with this metric in mind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
